{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file=open(\"train\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_count=0\n",
    "ham_count=0\n",
    "spam_dectionairy=dict()\n",
    "ham_dectionairy=dict()\n",
    "while True:\n",
    "    line=train_file.readline()\n",
    "    if line == '':\n",
    "        break\n",
    "    words=line.split()\n",
    "    if len(words)>0:\n",
    "        #print words[1]\n",
    "        if words[1]==\"spam\":\n",
    "            spam_count += 1\n",
    "            for i in range(2,len(words),2):\n",
    "                if words[i] in spam_dectionairy:\n",
    "                    spam_dectionairy[words[i]]+=int(float(words[i+1]))\n",
    "                else:\n",
    "                    spam_dectionairy[words[i]]=int(float(words[i+1]))\n",
    "        else:\n",
    "            ham_count += 1\n",
    "            for i in range(2,len(words),2):\n",
    "                if words[i] in ham_dectionairy:\n",
    "                    ham_dectionairy[words[i]]+=int(float(words[i+1]))\n",
    "                else:\n",
    "                    ham_dectionairy[words[i]]=int(float(words[i+1]))\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163\n",
      "3837\n"
     ]
    }
   ],
   "source": [
    "print spam_count\n",
    "print ham_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_prior=float(spam_count)/(spam_count+ham_count)\n",
    "ham_prior=1-spam_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam prior =  0.573666666667\n",
      "Ham prior =  0.426333333333\n"
     ]
    }
   ],
   "source": [
    "print 'Spam prior = ', spam_prior\n",
    "print 'Ham prior = ',ham_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words in spam =  1655369\n",
      "number of words in ham =  1577820\n",
      "number of distict words =  1000\n"
     ]
    }
   ],
   "source": [
    "spam_total_words_count=0\n",
    "ham_total_words_count=0\n",
    "distict_wrods_count=len(spam_dectionairy)\n",
    "for key in spam_dectionairy:\n",
    "    spam_total_words_count += spam_dectionairy[key]\n",
    "for key in ham_dectionairy:\n",
    "    ham_total_words_count += ham_dectionairy[key]\n",
    "    if key not in spam_dectionairy:\n",
    "        distict_wrods_count +=1\n",
    "print \"number of words in spam = \",spam_total_words_count\n",
    "print \"number of words in ham = \",ham_total_words_count\n",
    "print \"number of distict words = \",distict_wrods_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_liklihood_dictionairy=dict()\n",
    "ham_liklihood_dictionairy=dict()\n",
    "for key in spam_dectionairy:\n",
    "    spam_liklihood_dictionairy[key]=float(spam_dectionairy[key]+1)/(spam_total_words_count+distict_wrods_count)\n",
    "for key in ham_dectionairy:\n",
    "    ham_liklihood_dictionairy[key]=float(ham_dectionairy[key]+1)/(ham_total_words_count+distict_wrods_count)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most liklihood words for spam ['enron', 'a', 'corp', 'the', 'to']\n",
      "most liklihood words for ham ['aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'enron', 'the', 'to', 'a']\n"
     ]
    }
   ],
   "source": [
    "sorted_spam=sorted(spam_liklihood_dictionairy, key=spam_liklihood_dictionairy.get, reverse=True)\n",
    "soreted_ham=sorted(ham_liklihood_dictionairy, key=ham_liklihood_dictionairy.get,reverse=True)\n",
    "print \"most liklihood words for spam\",sorted_spam[0:5]\n",
    "print \"most liklihood words for ham\",soreted_ham[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove comman high likely words \n",
    "#for key in sorted_spam:\n",
    "#    spam_liklihood_dictionairy[key]=0\n",
    "#for i in soreted_ham:\n",
    "#    ham_liklihood_dictionairy[key]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  87.7 %\n"
     ]
    }
   ],
   "source": [
    "test_file=open(\"test\", 'r')\n",
    "predictions=[]\n",
    "accurate=0\n",
    "count=0\n",
    "while True:\n",
    "    line=test_file.readline()\n",
    "    if line =='':\n",
    "        break\n",
    "    words=line.split()\n",
    "    spam_probability=math.log(spam_prior)\n",
    "    ham_probability=math.log(ham_prior)\n",
    "    count +=1\n",
    "    for i in range(2,len(words),2):\n",
    "        if words[i] in spam_liklihood_dictionairy and spam_liklihood_dictionairy[words[i]]>0 :\n",
    "            spam_probability += (float(words[i+1])*math.log(spam_liklihood_dictionairy[words[i]]))\n",
    "        if words[i] in ham_liklihood_dictionairy and ham_liklihood_dictionairy[words[i]]>0:\n",
    "            ham_probability += (float(words[i+1])*math.log(ham_liklihood_dictionairy[words[i]]))\n",
    "    if  spam_probability>ham_probability and words[1] == \"spam\":\n",
    "        accurate +=1\n",
    "    elif ham_probability>spam_probability and words[1] == \"ham\": \n",
    "        accurate +=1\n",
    "\n",
    "print \"accuracy = \", (float(accurate)/count)*100,\"%\"\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## If I were a spammer I would use less of the words that indicate a spam and more of the words that indicate  ham so thn I can get more ham probability than spam probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
